{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face-recognition in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (from face-recognition) (7.1.2)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (from face-recognition) (19.22.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (from face-recognition) (8.3.1)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (from face-recognition) (0.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (from face-recognition) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vamsee\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install face-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cmake in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (3.22.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vamsee\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dlib in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (19.22.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vamsee\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face-recognition in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (from face-recognition) (0.3.0)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (from face-recognition) (19.22.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (from face-recognition) (8.3.1)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (from face-recognition) (7.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (from face-recognition) (1.19.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vamsee\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install face-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (8.3.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vamsee\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "import PIL.ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = face_recognition.load_image_file(\"group.jpg\")\n",
    "## load the image file into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find all face locations in the image\n",
    "face_locations = face_recognition.face_locations(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of faces detected are 10\n"
     ]
    }
   ],
   "source": [
    "### now the total count of faces detected are\n",
    "total_faces = len(face_locations)\n",
    "print(\"the total number of faces detected are {}\".format(total_faces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to draw the boxes on the detected faces, convert the image into PIL image format by using\n",
    "pilImage = PIL.Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the image is detected at location 274,677,326,625\n",
      "the image is detected at location 294,418,357,356\n",
      "the image is detected at location 281,792,343,729\n",
      "the image is detected at location 308,957,370,895\n",
      "the image is detected at location 285,498,337,446\n",
      "the image is detected at location 260,1068,322,1006\n",
      "the image is detected at location 260,315,322,252\n",
      "the image is detected at location 329,204,391,142\n",
      "the image is detected at location 211,875,274,812\n",
      "the image is detected at location 294,605,357,543\n"
     ]
    }
   ],
   "source": [
    "for face_loc in face_locations:\n",
    "    \n",
    "    top, right, bottom , left = face_loc\n",
    "    \n",
    "    print(\"the image is detected at location {},{},{},{}\".format(top, right, bottom, left))\n",
    "    \n",
    "    draw = PIL.ImageDraw.Draw(pilImage)\n",
    "    draw.rectangle([ left,top, right, bottom], outline = \"red\")\n",
    "\n",
    "pilImage.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## face landmark detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = face_recognition.load_image_file(\"group.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## detect face landmarks\n",
    "face_landmarks = face_recognition.face_landmarks(image)\n",
    "### the result is the list of dictionaries having the name of the location and coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total num of faces detacted are 10\n"
     ]
    }
   ],
   "source": [
    "print(\"the total num of faces detacted are {}\".format(len(face_landmarks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilImage2 = PIL.Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = PIL.ImageDraw.Draw(pilImage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the chin at location [(626, 289), (627, 296), (628, 302), (630, 309), (631, 315), (634, 321), (639, 325), (646, 328), (652, 330), (659, 329), (664, 325), (668, 321), (672, 316), (673, 310), (674, 304), (675, 298), (675, 291)]\n",
      "the left_eyebrow at location [(633, 286), (636, 284), (640, 283), (644, 283), (648, 285)]\n",
      "the right_eyebrow at location [(657, 285), (661, 284), (665, 284), (668, 285), (671, 287)]\n",
      "the nose_bridge at location [(653, 289), (653, 294), (653, 298), (653, 303)]\n",
      "the nose_tip at location [(647, 305), (650, 306), (652, 307), (655, 306), (657, 305)]\n",
      "the left_eye at location [(638, 290), (640, 288), (643, 288), (646, 290), (643, 290), (640, 290)]\n",
      "the right_eye at location [(659, 291), (661, 289), (664, 289), (666, 291), (664, 291), (661, 291)]\n",
      "the top_lip at location [(640, 311), (644, 309), (649, 309), (652, 309), (656, 309), (660, 309), (663, 311), (662, 311), (656, 310), (652, 311), (649, 310), (642, 311)]\n",
      "the bottom_lip at location [(663, 311), (660, 316), (656, 318), (652, 319), (649, 318), (644, 316), (640, 311), (642, 311), (649, 315), (652, 316), (656, 315), (662, 311)]\n",
      "the chin at location [(355, 314), (355, 322), (355, 331), (356, 339), (359, 346), (364, 352), (371, 357), (379, 360), (388, 362), (396, 361), (403, 357), (409, 352), (412, 346), (414, 339), (415, 331), (416, 324), (416, 317)]\n",
      "the left_eyebrow at location [(367, 306), (371, 303), (376, 303), (381, 304), (386, 307)]\n",
      "the right_eyebrow at location [(395, 308), (400, 306), (404, 306), (409, 307), (412, 310)]\n",
      "the nose_bridge at location [(390, 313), (390, 317), (390, 322), (390, 326)]\n",
      "the nose_tip at location [(383, 330), (386, 331), (389, 332), (392, 331), (395, 331)]\n",
      "the left_eye at location [(373, 313), (376, 312), (379, 312), (382, 314), (379, 314), (376, 314)]\n",
      "the right_eye at location [(397, 316), (400, 315), (403, 315), (406, 317), (403, 317), (400, 317)]\n",
      "the top_lip at location [(373, 337), (379, 335), (385, 335), (389, 336), (393, 335), (398, 336), (402, 339), (400, 339), (392, 338), (388, 337), (385, 337), (374, 337)]\n",
      "the bottom_lip at location [(402, 339), (397, 344), (392, 346), (388, 346), (384, 345), (378, 342), (373, 337), (374, 337), (384, 342), (388, 343), (392, 343), (400, 339)]\n",
      "the chin at location [(732, 301), (732, 308), (732, 316), (733, 323), (736, 331), (740, 337), (746, 342), (754, 346), (763, 347), (772, 346), (781, 342), (787, 337), (792, 331), (794, 323), (796, 315), (797, 307), (797, 299)]\n",
      "the left_eyebrow at location [(735, 295), (739, 292), (744, 291), (750, 292), (755, 294)]\n",
      "the right_eyebrow at location [(765, 292), (771, 290), (777, 289), (783, 290), (788, 293)]\n",
      "the nose_bridge at location [(760, 297), (760, 302), (760, 307), (759, 313)]\n",
      "the nose_tip at location [(754, 316), (757, 317), (760, 318), (763, 317), (767, 316)]\n",
      "the left_eye at location [(741, 300), (744, 298), (748, 298), (752, 300), (748, 300), (744, 300)]\n",
      "the right_eye at location [(771, 299), (774, 297), (778, 297), (781, 298), (778, 299), (774, 299)]\n",
      "the top_lip at location [(747, 324), (752, 322), (756, 321), (760, 321), (765, 321), (771, 321), (777, 323), (775, 323), (765, 323), (761, 323), (757, 323), (749, 324)]\n",
      "the bottom_lip at location [(777, 323), (772, 329), (766, 331), (761, 332), (757, 331), (752, 329), (747, 324), (749, 324), (757, 328), (761, 328), (765, 328), (775, 323)]\n",
      "the chin at location [(903, 334), (903, 340), (904, 347), (905, 354), (908, 361), (911, 367), (916, 372), (922, 376), (929, 377), (936, 375), (944, 371), (951, 366), (957, 360), (961, 352), (962, 344), (963, 335), (963, 326)]\n",
      "the left_eyebrow at location [(902, 327), (904, 324), (908, 323), (913, 323), (918, 323)]\n",
      "the right_eyebrow at location [(928, 322), (933, 319), (939, 317), (946, 317), (951, 321)]\n",
      "the nose_bridge at location [(923, 328), (923, 333), (923, 337), (923, 342)]\n",
      "the nose_tip at location [(920, 347), (922, 347), (925, 348), (928, 347), (931, 346)]\n",
      "the left_eye at location [(908, 332), (911, 330), (914, 329), (918, 331), (914, 331), (911, 332)]\n",
      "the right_eye at location [(933, 328), (937, 326), (940, 325), (944, 326), (941, 327), (937, 328)]\n",
      "the top_lip at location [(915, 355), (918, 353), (922, 352), (926, 352), (930, 351), (936, 351), (943, 352), (941, 352), (930, 353), (926, 354), (923, 354), (917, 355)]\n",
      "the bottom_lip at location [(943, 352), (937, 357), (932, 361), (927, 362), (924, 362), (919, 360), (915, 355), (917, 355), (923, 358), (927, 358), (931, 357), (941, 352)]\n",
      "the chin at location [(445, 295), (446, 302), (446, 309), (447, 316), (450, 322), (454, 328), (459, 332), (465, 336), (472, 338), (478, 336), (483, 332), (488, 327), (492, 322), (494, 316), (495, 310), (496, 304), (496, 297)]\n",
      "the left_eyebrow at location [(451, 295), (455, 292), (460, 291), (465, 293), (470, 295)]\n",
      "the right_eyebrow at location [(477, 295), (482, 293), (486, 292), (491, 293), (493, 296)]\n",
      "the nose_bridge at location [(474, 298), (474, 302), (474, 307), (474, 312)]\n",
      "the nose_tip at location [(467, 312), (470, 314), (473, 315), (476, 314), (479, 313)]\n",
      "the left_eye at location [(457, 298), (460, 297), (463, 297), (466, 299), (463, 299), (460, 299)]\n",
      "the right_eye at location [(479, 299), (482, 298), (486, 298), (488, 299), (485, 300), (482, 300)]\n",
      "the top_lip at location [(460, 318), (465, 318), (470, 319), (473, 319), (476, 319), (479, 319), (483, 318), (482, 319), (476, 320), (473, 321), (470, 320), (462, 319)]\n",
      "the bottom_lip at location [(483, 318), (479, 321), (476, 323), (472, 323), (469, 323), (465, 321), (460, 318), (462, 319), (469, 320), (473, 321), (476, 320), (482, 319)]\n",
      "the chin at location [(1006, 279), (1007, 286), (1007, 293), (1008, 300), (1010, 307), (1014, 313), (1019, 318), (1026, 322), (1034, 323), (1042, 321), (1049, 318), (1055, 313), (1059, 307), (1062, 300), (1062, 293), (1063, 286), (1063, 279)]\n",
      "the left_eyebrow at location [(1012, 275), (1015, 272), (1020, 270), (1025, 270), (1029, 271)]\n",
      "the right_eyebrow at location [(1038, 271), (1043, 269), (1048, 269), (1052, 271), (1056, 274)]\n",
      "the nose_bridge at location [(1033, 276), (1033, 282), (1033, 287), (1033, 292)]\n",
      "the nose_tip at location [(1028, 294), (1030, 295), (1033, 296), (1036, 295), (1039, 294)]\n",
      "the left_eye at location [(1017, 279), (1020, 277), (1024, 277), (1027, 279), (1023, 280), (1020, 280)]\n",
      "the right_eye at location [(1041, 279), (1044, 277), (1047, 276), (1050, 278), (1047, 279), (1044, 279)]\n",
      "the top_lip at location [(1020, 301), (1024, 299), (1029, 298), (1033, 299), (1038, 298), (1042, 298), (1047, 300), (1046, 300), (1038, 300), (1033, 300), (1029, 300), (1022, 301)]\n",
      "the bottom_lip at location [(1047, 300), (1043, 305), (1038, 308), (1034, 308), (1029, 308), (1024, 306), (1020, 301), (1022, 301), (1029, 305), (1034, 306), (1038, 305), (1046, 300)]\n",
      "the chin at location [(253, 279), (253, 286), (253, 293), (253, 300), (255, 306), (260, 311), (267, 315), (275, 318), (283, 319), (290, 319), (297, 316), (303, 312), (308, 307), (310, 301), (311, 295), (311, 289), (312, 283)]\n",
      "the left_eyebrow at location [(260, 277), (264, 273), (270, 272), (276, 273), (281, 275)]\n",
      "the right_eyebrow at location [(288, 276), (294, 274), (300, 274), (305, 276), (308, 280)]\n",
      "the nose_bridge at location [(285, 279), (284, 282), (284, 286), (284, 289)]\n",
      "the nose_tip at location [(278, 293), (281, 293), (284, 294), (287, 294), (290, 293)]\n",
      "the left_eye at location [(266, 279), (270, 279), (273, 279), (276, 280), (273, 280), (270, 280)]\n",
      "the right_eye at location [(292, 281), (295, 280), (298, 281), (301, 282), (298, 282), (295, 282)]\n",
      "the top_lip at location [(271, 300), (276, 299), (280, 298), (283, 299), (287, 298), (291, 299), (295, 301), (293, 301), (287, 300), (283, 300), (280, 299), (273, 300)]\n",
      "the bottom_lip at location [(295, 301), (291, 304), (287, 304), (283, 304), (280, 304), (276, 303), (271, 300), (273, 300), (280, 301), (283, 301), (287, 301), (293, 301)]\n",
      "the chin at location [(143, 350), (143, 357), (144, 364), (146, 372), (149, 378), (155, 384), (161, 389), (169, 393), (177, 394), (184, 392), (190, 388), (194, 382), (197, 376), (198, 369), (199, 362), (199, 355), (198, 348)]\n",
      "the left_eyebrow at location [(150, 344), (153, 341), (158, 340), (163, 340), (168, 342)]\n",
      "the right_eyebrow at location [(177, 341), (182, 339), (186, 339), (191, 340), (194, 343)]\n",
      "the nose_bridge at location [(174, 347), (174, 352), (175, 358), (175, 363)]\n",
      "the nose_tip at location [(168, 365), (172, 366), (175, 367), (178, 366), (181, 365)]\n",
      "the left_eye at location [(156, 348), (159, 347), (162, 347), (165, 348), (162, 348), (159, 349)]\n",
      "the right_eye at location [(180, 348), (183, 346), (186, 346), (189, 347), (186, 348), (183, 348)]\n",
      "the top_lip at location [(161, 372), (166, 371), (171, 371), (175, 371), (179, 370), (184, 370), (188, 371), (186, 371), (179, 372), (175, 373), (172, 372), (163, 373)]\n",
      "the bottom_lip at location [(188, 371), (185, 378), (180, 381), (176, 382), (172, 381), (166, 378), (161, 372), (163, 373), (172, 377), (176, 378), (180, 377), (186, 371)]\n",
      "the chin at location [(817, 231), (817, 238), (818, 244), (818, 251), (820, 257), (824, 262), (830, 266), (838, 269), (846, 269), (854, 269), (862, 267), (867, 264), (871, 259), (873, 252), (874, 246), (875, 240), (876, 233)]\n",
      "the left_eyebrow at location [(823, 224), (827, 221), (832, 220), (837, 220), (842, 222)]\n",
      "the right_eyebrow at location [(851, 222), (856, 221), (861, 221), (866, 222), (870, 226)]\n",
      "the nose_bridge at location [(847, 226), (847, 230), (846, 234), (846, 238)]\n",
      "the nose_tip at location [(840, 242), (843, 242), (846, 243), (850, 242), (853, 242)]\n",
      "the left_eye at location [(829, 229), (832, 228), (835, 228), (839, 229), (835, 230), (832, 230)]\n",
      "the right_eye at location [(854, 230), (857, 229), (861, 229), (864, 231), (860, 231), (857, 230)]\n",
      "the top_lip at location [(832, 249), (837, 247), (842, 246), (846, 247), (851, 246), (856, 247), (861, 250), (860, 250), (851, 248), (846, 249), (842, 248), (833, 249)]\n",
      "the bottom_lip at location [(861, 250), (856, 254), (851, 255), (846, 256), (842, 255), (836, 253), (832, 249), (833, 249), (842, 252), (846, 253), (851, 253), (860, 250)]\n",
      "the chin at location [(554, 315), (553, 321), (552, 328), (553, 335), (554, 342), (557, 348), (561, 353), (567, 357), (573, 359), (581, 359), (588, 357), (595, 353), (601, 348), (604, 341), (606, 334), (608, 326), (608, 318)]\n",
      "the left_eyebrow at location [(556, 309), (559, 306), (563, 305), (568, 306), (572, 308)]\n",
      "the right_eyebrow at location [(581, 308), (586, 307), (592, 307), (597, 309), (601, 313)]\n",
      "the nose_bridge at location [(576, 313), (575, 318), (575, 323), (574, 328)]\n",
      "the nose_tip at location [(569, 329), (571, 331), (574, 332), (578, 331), (581, 330)]\n",
      "the left_eye at location [(560, 313), (563, 312), (567, 312), (569, 314), (566, 314), (563, 314)]\n",
      "the right_eye at location [(585, 315), (588, 313), (592, 313), (594, 315), (591, 316), (588, 316)]\n",
      "the top_lip at location [(563, 337), (567, 335), (571, 335), (575, 336), (579, 335), (584, 336), (589, 338), (588, 338), (578, 337), (575, 337), (571, 337), (564, 337)]\n",
      "the bottom_lip at location [(589, 338), (584, 342), (578, 344), (574, 344), (571, 344), (567, 342), (563, 337), (564, 337), (571, 341), (575, 341), (579, 341), (588, 338)]\n"
     ]
    }
   ],
   "source": [
    "## create PIL object to draw the landmarks on the face\n",
    "for face_landmark in face_landmarks:\n",
    "    \n",
    "    for name, location in face_landmark.items():\n",
    "        \n",
    "        print(\"the {} at location {}\".format(name, location))\n",
    "        \n",
    "        draw.line(location, fill=\"green\", width=2)\n",
    "       \n",
    "\n",
    "pilImage2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## face encoding system for facial recongnition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = face_recognition.load_image_file(\"me.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_encodings = face_recognition.face_encodings(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11464708  0.0832312   0.03477233 -0.04889316 -0.01770093 -0.05686331\n",
      " -0.03507356 -0.07244468  0.1527233  -0.0229215   0.16235653 -0.08779538\n",
      " -0.12909114 -0.0616494  -0.01640946  0.05490454 -0.0457334  -0.18359931\n",
      "  0.0041033  -0.10509349  0.04617211 -0.00251381 -0.06713556  0.11181948\n",
      " -0.26016271 -0.29278374 -0.0632524  -0.17895709 -0.04887182 -0.08850699\n",
      " -0.00914397  0.12753482 -0.15999441 -0.06349951  0.03180765  0.16431174\n",
      "  0.03646139  0.02603384  0.1395013   0.0239003  -0.14169869  0.02234108\n",
      "  0.09064393  0.32930821  0.15396568  0.05932804 -0.00802652  0.0142692\n",
      "  0.14995882 -0.2199285   0.09379326  0.11469807  0.15316355  0.05741631\n",
      "  0.12156082 -0.11271462  0.04486743  0.05531057 -0.23064262  0.08455133\n",
      "  0.01487575 -0.00817451 -0.03322026 -0.04579557  0.25082821  0.13641872\n",
      " -0.11276098 -0.03070282  0.10015731 -0.14296389 -0.05718958  0.07597118\n",
      " -0.09836744 -0.14658119 -0.24335249  0.11622719  0.38303888  0.12526034\n",
      " -0.2171113   0.0723056  -0.02482475 -0.02270631  0.07333537 -0.00206521\n",
      " -0.10321075  0.02167754 -0.07964344  0.00076372  0.21669322  0.06153347\n",
      " -0.02806905  0.14543255 -0.06219607  0.04182945  0.03979244  0.04104441\n",
      " -0.15253702 -0.00634503 -0.10239834 -0.05279347  0.07743954 -0.03540653\n",
      " -0.03379876  0.10981276 -0.23283687  0.13475648 -0.0072405  -0.02586388\n",
      " -0.03222417  0.09353349 -0.1025414  -0.02782695  0.13654353 -0.24459259\n",
      "  0.13854426  0.07955314 -0.01886294  0.11465546  0.07275376 -0.01555142\n",
      "  0.01360942  0.00639642 -0.12598535 -0.08256483  0.11049313 -0.06439231\n",
      "  0.05628891  0.01547834]\n"
     ]
    }
   ],
   "source": [
    "if len(face_encodings)==0:\n",
    "    print(\"no faces are detected\")\n",
    "\n",
    "else:\n",
    "    print(face_encodings[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a self exercise, you can try replacing the images with your own images and find if the images matches with the new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = face_recognition.load_image_file(\"sam1.jpg\")\n",
    "image2 = face_recognition.load_image_file(\"bard1.jpg\")\n",
    "image3 = face_recognition.load_image_file(\"ange.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_encoding_img1 = face_recognition.face_encodings(image1)[0]\n",
    "face_encoding_img2 = face_recognition.face_encodings(image2)[0]\n",
    "face_encoding_img3 = face_recognition.face_encodings(image3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_encodings = [face_encoding_img1, face_encoding_img2, face_encoding_img3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = face_recognition.load_image_file(\"sam_fam2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img_face_encoding = face_recognition.face_encodings(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_img_face_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the face is identified as sam\n"
     ]
    }
   ],
   "source": [
    "for encodings in new_img_face_encoding:\n",
    "    \n",
    "    name =\"empty\"\n",
    "    \n",
    "    result = face_recognition.api.compare_faces(list_of_encodings, encodings, tolerance=0.6)\n",
    "    \n",
    "    if result[0]:\n",
    "        print(\"the face is identified as sam\")\n",
    "    elif result[1]:\n",
    "        print(\"the face is identified as AA\")\n",
    "    elif  result[2]:\n",
    "        print(\"the face is identified as Ange\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### increase the image size if the system is not able to identify the faces properly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = face_recognition.load_image_file(\"group.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image_locations = face_recognition.face_locations(new_image, number_of_times_to_upsample=2)\n",
    "new_image_encodings = face_recognition.face_encodings(new_image, known_face_locations=new_image_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the face is identified as AA\n",
      "the face is identified as sam\n"
     ]
    }
   ],
   "source": [
    "for encodings in new_image_encodings:\n",
    "    \n",
    "    name =\"empty\"\n",
    "    \n",
    "    result = face_recognition.api.compare_faces(list_of_encodings, encodings, tolerance=0.6)\n",
    "    \n",
    "    if result[0]:\n",
    "        print(\"the face is identified as sam\")\n",
    "    elif result[1]:\n",
    "        print(\"the face is identified as AA\")\n",
    "    elif  result[2]:\n",
    "        print(\"the face is identified as Ange\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying filters on the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = face_recognition.load_image_file(\"group.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find all facial landmarks \n",
    "face_landmarks = face_recognition.face_landmarks(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(face_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilImage = PIL.Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = PIL.ImageDraw.Draw(pilImage, \"RGBA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face_landmark in face_landmarks:\n",
    "    \n",
    "    draw.line(face_landmark[\"left_eyebrow\"], fill=(120,0,120,100), width=4)\n",
    "    draw.line(face_landmark[\"right_eyebrow\"], fill=(120,0,120,100), width=4)\n",
    "    \n",
    "    draw.polygon(face_landmark[\"top_lip\"], fill=(0,120,50,100))\n",
    "    draw.polygon(face_landmark[\"bottom_lip\"], fill=(0,120,50,100))\n",
    "\n",
    "pilImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chin': [(626, 289),\n",
       "  (627, 296),\n",
       "  (628, 302),\n",
       "  (630, 309),\n",
       "  (631, 315),\n",
       "  (634, 321),\n",
       "  (639, 325),\n",
       "  (646, 328),\n",
       "  (652, 330),\n",
       "  (659, 329),\n",
       "  (664, 325),\n",
       "  (668, 321),\n",
       "  (672, 316),\n",
       "  (673, 310),\n",
       "  (674, 304),\n",
       "  (675, 298),\n",
       "  (675, 291)],\n",
       " 'left_eyebrow': [(633, 286), (636, 284), (640, 283), (644, 283), (648, 285)],\n",
       " 'right_eyebrow': [(657, 285), (661, 284), (665, 284), (668, 285), (671, 287)],\n",
       " 'nose_bridge': [(653, 289), (653, 294), (653, 298), (653, 303)],\n",
       " 'nose_tip': [(647, 305), (650, 306), (652, 307), (655, 306), (657, 305)],\n",
       " 'left_eye': [(638, 290),\n",
       "  (640, 288),\n",
       "  (643, 288),\n",
       "  (646, 290),\n",
       "  (643, 290),\n",
       "  (640, 290)],\n",
       " 'right_eye': [(659, 291),\n",
       "  (661, 289),\n",
       "  (664, 289),\n",
       "  (666, 291),\n",
       "  (664, 291),\n",
       "  (661, 291)],\n",
       " 'top_lip': [(640, 311),\n",
       "  (644, 309),\n",
       "  (649, 309),\n",
       "  (652, 309),\n",
       "  (656, 309),\n",
       "  (660, 309),\n",
       "  (663, 311),\n",
       "  (662, 311),\n",
       "  (656, 310),\n",
       "  (652, 311),\n",
       "  (649, 310),\n",
       "  (642, 311)],\n",
       " 'bottom_lip': [(663, 311),\n",
       "  (660, 316),\n",
       "  (656, 318),\n",
       "  (652, 319),\n",
       "  (649, 318),\n",
       "  (644, 316),\n",
       "  (640, 311),\n",
       "  (642, 311),\n",
       "  (649, 315),\n",
       "  (652, 316),\n",
       "  (656, 315),\n",
       "  (662, 311)]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_landmarks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding the similar face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib in c:\\users\\vamsee\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\vamsee\\anaconda3\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\vamsee\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_image = face_recognition.load_image_file(\"me.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_img_encoding = face_recognition.face_encodings(known_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_face_distance = 1.0\n",
    "best_face = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maleactors\\AA2.jpg\n",
      "maleactors\\act1.jpg\n",
      "maleactors\\act10.jpg\n",
      "maleactors\\act12.jpg\n",
      "maleactors\\act2.jpg\n",
      "maleactors\\act5.jpg\n",
      "maleactors\\act6.jpg\n",
      "maleactors\\act7.jpg\n",
      "maleactors\\act8.jpg\n",
      "maleactors\\act9.jpg\n"
     ]
    }
   ],
   "source": [
    "for face in Path(\"maleactors\").glob(\"*.jpg\"):\n",
    "    \n",
    "    \n",
    "    new_face_image = face_recognition.load_image_file(face)\n",
    "    new_face_encoding = face_recognition.face_encodings(new_face_image)\n",
    "    \n",
    "    face_distance = face_recognition.face_distance(new_face_encoding, known_img_encoding)\n",
    "    print(face)\n",
    "    if face_distance <best_face_distance:\n",
    "        \n",
    "        best_face_distance= face_distance\n",
    "        best_face = new_face_image\n",
    "\n",
    "pilImage = PIL.Image.fromarray(best_face)\n",
    "pilImage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
